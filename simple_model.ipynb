{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as utils\n",
    "import torch.optim as optim\n",
    "from logger import Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<type 'numpy.ndarray'>\n",
      "(30000, 24)\n"
     ]
    }
   ],
   "source": [
    "## getting the data as panda frame and then converting to the corrosponding numpy matrix\n",
    "\n",
    "location='default-of-credit-card-clients.csv'\n",
    "df=pd.read_csv(location,header=None)\n",
    "\n",
    "df=df[2:]\n",
    "print(type(df))\n",
    "df_num=(df.astype(float)).values\n",
    "df_num=df_num[:,1:]\n",
    "print(type(df_num))\n",
    "print(df_num.shape)\n",
    "\n",
    "def to_np(x):\n",
    "    return x.data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2.00000000e+04   2.00000000e+00   2.00000000e+00   1.00000000e+00\n",
      "   2.40000000e+01   2.00000000e+00   2.00000000e+00  -1.00000000e+00\n",
      "  -1.00000000e+00  -2.00000000e+00  -2.00000000e+00   3.91300000e+03\n",
      "   3.10200000e+03   6.89000000e+02   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   6.89000000e+02   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   1.00000000e+00]\n",
      "<class 'torch.DoubleTensor'>\n",
      "<class 'torch.DoubleTensor'>\n",
      "<class 'torch.FloatTensor'>\n",
      "<class 'torch.FloatTensor'>\n",
      "\n",
      "torch.Size([30000, 23])\n",
      "torch.Size([30000, 1])\n",
      "\n",
      "('SIZE of labels: ', torch.Size([30000, 1]))\n",
      "('No of batches:', 7500, ' of batch size: ', 4)\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "## Data forming using tensors\n",
    "\n",
    "df_num.shape\n",
    "print(df_num[0])\n",
    "data=df_num[:,:23]\n",
    "labels=df_num[:,23:]\n",
    "data=torch.from_numpy(data)\n",
    "labels=torch.from_numpy(labels)\n",
    "print(type(data))\n",
    "print(type(labels))\n",
    "data=data.float()\n",
    "labels=labels.float()\n",
    "print(type(data))\n",
    "print(type(labels))\n",
    "raw_input()\n",
    "print(data.size())\n",
    "print(labels.size())\n",
    "raw_input()\n",
    "## Hyperparameters\n",
    "batchsize=4\n",
    "nb_epochs=1\n",
    "learning_rate=0.0001\n",
    "momentum=0.01\n",
    "print(\"SIZE of labels: \",labels.size())\n",
    "## [IMPORTANT for forming the dataset]\n",
    "\n",
    "## the condition is that the dataset should just be a torch tensor, however while raining the input to the model\n",
    "## should be a Variable torch tensor\n",
    "dataset=utils.TensorDataset(data,labels)\n",
    "dataloader=utils.DataLoader(dataset=dataset,batch_size=batchsize)\n",
    "print('No of batches:',len(dataloader),' of batch size: ',batchsize)\n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TestNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TestNet,self).__init__()\n",
    "        self.fc1_1=nn.Linear(23,12)\n",
    "        self.fc1_2=nn.Linear(12,6)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.fc1=nn.Linear(23,6)\n",
    "        self.fc2=nn.Linear(6,3)\n",
    "        self.fc3=nn.Linear(3,1)\n",
    "        self.sigmoid=nn.Sigmoid()\n",
    "    def forward(self,x):\n",
    "        out=self.fc1_1(x)\n",
    "        out=self.relu(out)\n",
    "        out=self.fc1_2(out)\n",
    "        out=self.relu(out)\n",
    "        out_1=self.fc1(x)\n",
    "        out=out+out_1\n",
    "        out=self.relu(self.fc2(out))\n",
    "        out=self.sigmoid(self.fc3(out))\n",
    "        return out\n",
    "net=TestNet()\n",
    "loss_criteria=nn.BCELoss()\n",
    "optimizer=optim.Adam(params=net.parameters(),lr=0.001,weight_decay=0.0001)\n",
    "logger=Logger('./logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('iter: ', 100, ' loss: ', 0.6165459156036377)\n",
      "('iter: ', 200, ' loss: ', 0.5793635845184326)\n",
      "('iter: ', 300, ' loss: ', 0.6270204186439514)\n",
      "('iter: ', 400, ' loss: ', 0.6160985827445984)\n",
      "('iter: ', 500, ' loss: ', 0.49757567048072815)\n",
      "('iter: ', 600, ' loss: ', 0.47514617443084717)\n",
      "('iter: ', 700, ' loss: ', 0.45939192175865173)\n",
      "('iter: ', 800, ' loss: ', 0.5880136489868164)\n",
      "('iter: ', 900, ' loss: ', 0.5841240286827087)\n",
      "('iter: ', 1000, ' loss: ', 0.9206920862197876)\n",
      "('iter: ', 1100, ' loss: ', 0.39546939730644226)\n",
      "('iter: ', 1200, ' loss: ', 0.38110196590423584)\n",
      "('iter: ', 1300, ' loss: ', 0.37230220437049866)\n",
      "('iter: ', 1400, ' loss: ', 0.5686999559402466)\n",
      "('iter: ', 1500, ' loss: ', 0.3464188873767853)\n",
      "('iter: ', 1600, ' loss: ', 0.5663537979125977)\n",
      "('iter: ', 1700, ' loss: ', 0.5653536319732666)\n",
      "('iter: ', 1800, ' loss: ', 0.3298242390155792)\n",
      "('iter: ', 1900, ' loss: ', 0.5643375515937805)\n",
      "('iter: ', 2000, ' loss: ', 0.5638386607170105)\n",
      "('iter: ', 2100, ' loss: ', 0.31606215238571167)\n",
      "('iter: ', 2200, ' loss: ', 0.8181287050247192)\n",
      "('iter: ', 2300, ' loss: ', 0.8196245431900024)\n",
      "('iter: ', 2400, ' loss: ', 0.3054417669773102)\n",
      "('iter: ', 2500, ' loss: ', 0.562563419342041)\n",
      "('iter: ', 2600, ' loss: ', 0.830605685710907)\n",
      "('iter: ', 2700, ' loss: ', 0.29102951288223267)\n",
      "('iter: ', 2800, ' loss: ', 0.2879330813884735)\n",
      "('iter: ', 2900, ' loss: ', 0.2843579053878784)\n",
      "('iter: ', 3000, ' loss: ', 0.5624054074287415)\n",
      "('iter: ', 3100, ' loss: ', 0.2786466181278229)\n",
      "('iter: ', 3200, ' loss: ', 0.5625346899032593)\n",
      "('iter: ', 3300, ' loss: ', 0.5625172257423401)\n",
      "('iter: ', 3400, ' loss: ', 0.5625544786453247)\n",
      "('iter: ', 3500, ' loss: ', 0.5626860857009888)\n",
      "('iter: ', 3600, ' loss: ', 0.5626656413078308)\n",
      "('iter: ', 3700, ' loss: ', 0.5628001689910889)\n",
      "('iter: ', 3800, ' loss: ', 0.269162654876709)\n",
      "('iter: ', 3900, ' loss: ', 0.8606781959533691)\n",
      "('iter: ', 4000, ' loss: ', 0.8617586493492126)\n",
      "('iter: ', 4100, ' loss: ', 0.2708069682121277)\n",
      "('iter: ', 4200, ' loss: ', 0.5624850988388062)\n",
      "('iter: ', 4300, ' loss: ', 0.28475144505500793)\n",
      "('iter: ', 4400, ' loss: ', 0.5623416900634766)\n",
      "('iter: ', 4500, ' loss: ', 0.5623394250869751)\n",
      "('iter: ', 4600, ' loss: ', 0.5623393058776855)\n",
      "('iter: ', 4700, ' loss: ', 0.2814050018787384)\n",
      "('iter: ', 4800, ' loss: ', 0.5624915361404419)\n",
      "('iter: ', 4900, ' loss: ', 0.27159368991851807)\n",
      "('iter: ', 5000, ' loss: ', 0.5631154775619507)\n",
      "('iter: ', 5100, ' loss: ', 0.5634369850158691)\n",
      "('iter: ', 5200, ' loss: ', 0.862596869468689)\n",
      "('iter: ', 5300, ' loss: ', 0.5629842281341553)\n",
      "('iter: ', 5400, ' loss: ', 0.26628080010414124)\n",
      "('iter: ', 5500, ' loss: ', 0.2615223228931427)\n",
      "('iter: ', 5600, ' loss: ', 0.25383231043815613)\n",
      "('iter: ', 5700, ' loss: ', 0.2489469051361084)\n",
      "('iter: ', 5800, ' loss: ', 0.24533505737781525)\n",
      "('iter: ', 5900, ' loss: ', 0.24251089990139008)\n",
      "('iter: ', 6000, ' loss: ', 0.5659956932067871)\n",
      "('iter: ', 6100, ' loss: ', 0.8936362862586975)\n",
      "('iter: ', 6200, ' loss: ', 0.24047686159610748)\n",
      "('iter: ', 6300, ' loss: ', 0.5661982893943787)\n",
      "('iter: ', 6400, ' loss: ', 0.23762430250644684)\n",
      "('iter: ', 6500, ' loss: ', 0.23414920270442963)\n",
      "('iter: ', 6600, ' loss: ', 0.23003257811069489)\n",
      "('iter: ', 6700, ' loss: ', 0.2336304932832718)\n",
      "('iter: ', 6800, ' loss: ', 0.8997613191604614)\n",
      "('iter: ', 6900, ' loss: ', 0.5662404298782349)\n",
      "('iter: ', 7000, ' loss: ', 0.24054645001888275)\n",
      "('iter: ', 7100, ' loss: ', 0.23856289684772491)\n",
      "('iter: ', 7200, ' loss: ', 0.567186713218689)\n",
      "('iter: ', 7300, ' loss: ', 0.23424655199050903)\n",
      "('iter: ', 7400, ' loss: ', 0.5670165419578552)\n",
      "('iter: ', 7500, ' loss: ', 0.8917394876480103)\n",
      "('iter: ', 7600, ' loss: ', 0.565787672996521)\n",
      "('iter: ', 7700, ' loss: ', 0.5661309957504272)\n",
      "('iter: ', 7800, ' loss: ', 0.24035920202732086)\n",
      "('iter: ', 7900, ' loss: ', 0.2403060644865036)\n",
      "('iter: ', 8000, ' loss: ', 0.8902336955070496)\n",
      "('iter: ', 8100, ' loss: ', 0.5658011436462402)\n",
      "('iter: ', 8200, ' loss: ', 0.8836933970451355)\n",
      "('iter: ', 8300, ' loss: ', 0.8847653269767761)\n",
      "('iter: ', 8400, ' loss: ', 0.5649008750915527)\n",
      "('iter: ', 8500, ' loss: ', 0.882824182510376)\n",
      "('iter: ', 8600, ' loss: ', 0.24760204553604126)\n",
      "('iter: ', 8700, ' loss: ', 0.8839734792709351)\n",
      "('iter: ', 8800, ' loss: ', 0.5648012161254883)\n",
      "('iter: ', 8900, ' loss: ', 0.5652649998664856)\n",
      "('iter: ', 9000, ' loss: ', 0.5654940009117126)\n",
      "('iter: ', 9100, ' loss: ', 0.8807163834571838)\n",
      "('iter: ', 9200, ' loss: ', 0.5647987723350525)\n",
      "('iter: ', 9300, ' loss: ', 0.25105637311935425)\n",
      "('iter: ', 9400, ' loss: ', 0.5642513036727905)\n",
      "('iter: ', 9500, ' loss: ', 0.2541367709636688)\n",
      "('iter: ', 9600, ' loss: ', 0.25521349906921387)\n",
      "('iter: ', 9700, ' loss: ', 0.8766053915023804)\n",
      "('iter: ', 9800, ' loss: ', 0.25497201085090637)\n",
      "('iter: ', 9900, ' loss: ', 0.2584412097930908)\n",
      "('iter: ', 10000, ' loss: ', 0.25718459486961365)\n",
      "('iter: ', 10100, ' loss: ', 0.5640757083892822)\n",
      "('iter: ', 10200, ' loss: ', 1.1828227043151855)\n",
      "('iter: ', 10300, ' loss: ', 0.2545261085033417)\n",
      "('iter: ', 10400, ' loss: ', 0.5642010569572449)\n",
      "('iter: ', 10500, ' loss: ', 0.5643150210380554)\n",
      "('iter: ', 10600, ' loss: ', 0.8756385445594788)\n",
      "('iter: ', 10700, ' loss: ', 1.1877124309539795)\n",
      "('iter: ', 10800, ' loss: ', 0.2551119029521942)\n",
      "('iter: ', 10900, ' loss: ', 0.5639845132827759)\n",
      "('iter: ', 11000, ' loss: ', 0.2545316815376282)\n",
      "('iter: ', 11100, ' loss: ', 0.563926637172699)\n",
      "('iter: ', 11200, ' loss: ', 0.564072847366333)\n",
      "('iter: ', 11300, ' loss: ', 0.8732290267944336)\n",
      "('iter: ', 11400, ' loss: ', 0.5643446445465088)\n",
      "('iter: ', 11500, ' loss: ', 0.8761597275733948)\n",
      "('iter: ', 11600, ' loss: ', 0.5635895729064941)\n",
      "('iter: ', 11700, ' loss: ', 0.5629804134368896)\n",
      "('iter: ', 11800, ' loss: ', 0.850382924079895)\n",
      "('iter: ', 11900, ' loss: ', 0.27649715542793274)\n",
      "('iter: ', 12000, ' loss: ', 0.8474647998809814)\n",
      "('iter: ', 12100, ' loss: ', 0.2783691883087158)\n",
      "('iter: ', 12200, ' loss: ', 0.27423974871635437)\n",
      "('iter: ', 12300, ' loss: ', 0.5627681016921997)\n",
      "('iter: ', 12400, ' loss: ', 0.5631014108657837)\n",
      "('iter: ', 12500, ' loss: ', 0.5635626316070557)\n",
      "('iter: ', 12600, ' loss: ', 0.2566983699798584)\n",
      "('iter: ', 12700, ' loss: ', 0.8677908778190613)\n",
      "('iter: ', 12800, ' loss: ', 0.5632885694503784)\n",
      "('iter: ', 12900, ' loss: ', 1.165259838104248)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-21d6f9bd5933>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m## forward propogate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;31m## get the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_criteria\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/fenildoshi/Envs/snakes/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-fa78d07a6c5c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/fenildoshi/Envs/snakes/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/fenildoshi/Envs/snakes/lib/python2.7/site-packages/torch/nn/modules/linear.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/fenildoshi/Envs/snakes/lib/python2.7/site-packages/torch/nn/_functions/linear.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_for_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_steps=50000\n",
    "iter_per_epoch=len(dataloader)\n",
    "data_iter=iter(dataloader)\n",
    "\n",
    "for i in range(num_steps):\n",
    "    ## reset the data_iter \n",
    "    if((i+1)%iter_per_epoch==0):\n",
    "        data_iter=iter(dataloader)\n",
    "    \n",
    "    train_x,train_y=next(data_iter)\n",
    "    train_x=Variable(train_x)\n",
    "    train_y=Variable(train_y)   ## HACKY FIX as train_y already becomes a Variable\n",
    "        \n",
    "    ## creating the architecture , this contains a list of all the parameters\n",
    "    ## loss function\n",
    "\n",
    "\n",
    "    ## forward propogate\n",
    "    out=net(train_x)\n",
    "    ## get the loss\n",
    "    loss=loss_criteria(out,train_y)\n",
    "    ## zero the grad\n",
    "    optimizer.zero_grad()\n",
    "    ## backprop\n",
    "    loss.backward()\n",
    "    ## update the paramters\n",
    "    optimizer.step()\n",
    "    \n",
    "    if((i+1)%100==0):\n",
    "        print(\"iter: \",i+1,\" loss: \",loss.data[0])\n",
    "\n",
    "    info={\n",
    "        'loss':loss.data[0]\n",
    "    }\n",
    "    for tag,val in info.items():\n",
    "        logger.scalar_summary(tag,val,i+1)\n",
    "        \n",
    "#     for tag, value in net.named_parameters():\n",
    "#         tag = tag.replace('.', '/')\n",
    "#         logger.histo_summary(tag, to_np(value),i)\n",
    "#         logger.histo_summary(tag+'/grad', to_np(value.grad),i)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
